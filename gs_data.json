{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "n6WBCgUAAAAJ&hl", "source": "AUTHOR_PROFILE_PAGE", "name": "Xiangyang Li", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=n6WBCgUAAAAJ&citpid=35", "affiliation": "Assitant Professor, Institute of Computing Technology, Chinese Academy of Sciences", "organization": 8095408014149788983, "interests": ["Computer Vision", "MultiModal Perception"], "email_domain": "@ict.ac.cn", "homepage": "https://xiangyangli20.github.io/", "citedby": 621, "publications": {"n6WBCgUAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Scene recognition with cnns: objects, scales and dataset bias", "pub_year": "2016"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:u5HHmVD_uO8C", "num_citations": 224, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7079907706154402741", "cites_id": ["7079907706154402741"]}, "n6WBCgUAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Know more say less: Image captioning based on scene graphs", "pub_year": "2019"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:ufrVoPGSRksC", "num_citations": 161, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5275307314855811324", "cites_id": ["5275307314855811324"]}, "n6WBCgUAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning object context for dense captioning", "pub_year": "2019"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:_FxGoFyzp5QC", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8072850415729994703", "cites_id": ["8072850415729994703"]}, "n6WBCgUAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual relationship detection with object spatial distribution", "pub_year": "2017"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:Y0pCki6q_DkC", "num_citations": 29, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16832443355805679279", "cites_id": ["16832443355805679279"]}, "n6WBCgUAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Image captioning with both object and scene information", "pub_year": "2016"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:9yKSN-GCB0IC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17281068068039378431", "cites_id": ["17281068068039378431"]}, "n6WBCgUAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bundled Object Context for Referring Expressions", "pub_year": "2018"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:eQOLeE2rZwMC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10677362592677458511", "cites_id": ["10677362592677458511"]}, "n6WBCgUAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Class agnostic image common object detection", "pub_year": "2019"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:WF5omc3nYNoC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2546658462560792362", "cites_id": ["2546658462560792362"]}, "n6WBCgUAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Where and what to eat: Simultaneous restaurant and dish recognition from food image", "pub_year": "2016"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:qjMakFHDy7sC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12635427713984282892", "cites_id": ["12635427713984282892"]}, "n6WBCgUAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "ISIA at the ImageCLEF 2017 Image Caption Task.", "pub_year": "2017"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:Tyk-4Ss8FVUC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12724558601869268632", "cites_id": ["12724558601869268632"]}, "n6WBCgUAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The retrieval of shoeprint images based on the integral histogram of the gabor transform domain", "pub_year": "2014"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:IjCSPb-OGe4C", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13232468699800587141", "cites_id": ["13232468699800587141"]}, "n6WBCgUAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Modality-specific and hierarchical feature learning for RGB-D hand-held object recognition", "pub_year": "2017"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:u-x6o8ySG0sC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4810219046994956147", "cites_id": ["4810219046994956147"]}, "n6WBCgUAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dataset bias in few-shot image recognition", "pub_year": "2022"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:hqOjcs7Dif8C", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18195113694858589468", "cites_id": ["18195113694858589468"]}, "n6WBCgUAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multifaceted Analysis of Fine-Tuning in a Deep Model for Visual Recognition", "pub_year": "2020"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:roLk4NBRz8UC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9923850667860896440", "cites_id": ["9923850667860896440"]}, "n6WBCgUAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Joint Learning of CNN and LSTM for Image Captioning.", "pub_year": "2016"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:d1gkVwhDpl0C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13676303595004466488", "cites_id": ["13676303595004466488"]}, "n6WBCgUAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "KERM: Knowledge Enhanced Reasoning for Vision-and-Language Navigation", "pub_year": "2023"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:5nxA0vEk-isC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13177967772358702893", "cites_id": ["13177967772358702893"]}, "n6WBCgUAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GridMM: Grid Memory Map for Vision-and-Language Navigation", "pub_year": "2023"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:3fE2CSJIrl8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10041460103552490212", "cites_id": ["10041460103552490212"]}, "n6WBCgUAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Heterogeneous convolutional neural networks for visual recognition", "pub_year": "2016"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:2osOgNQ5qMEC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3623799739357580932", "cites_id": ["3623799739357580932"]}, "n6WBCgUAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Combining heterogeneous features for 3D hand-held object recognition", "pub_year": "2014"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:zYLM7Y9cAGgC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15033860174246794815", "cites_id": ["15033860174246794815"]}, "n6WBCgUAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Membridge: Video-language pre-training with memory-augmented inter-modality bridge", "pub_year": "2023"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:kNdYIx-mwKoC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17099613632874022797", "cites_id": ["17099613632874022797"]}, "n6WBCgUAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Expressional region retrieval", "pub_year": "2020"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:Se3iqnhoufwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16824123180458327644", "cites_id": ["16824123180458327644"]}, "n6WBCgUAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multipath convolutional-recursive neural networks for object recognition", "pub_year": "2014"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:UeHWp8X0CEIC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=624150874712729697", "cites_id": ["624150874712729697"]}, "n6WBCgUAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TransWeaver: Weave Image Pairs for Class Agnostic Common Object Detection", "pub_year": "2023"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:MXK_kJrjxJIC", "num_citations": 0}, "n6WBCgUAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Focus and Align: Learning Tube Tokens for Video-Language Pre-training", "pub_year": "2022"}, "filled": false, "author_pub_id": "n6WBCgUAAAAJ:0EnyYjriUFMC", "num_citations": 0}}, "citedby5y": 579, "hindex": 11, "hindex5y": 10, "i10index": 12, "i10index5y": 11, "cites_per_year": {"2015": 3, "2016": 5, "2017": 31, "2018": 48, "2019": 90, "2020": 82, "2021": 106, "2022": 130, "2023": 120}, "updated": "2023-12-14 07:26:14.140858"}